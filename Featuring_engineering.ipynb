{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featuring engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feturing_engineering():\n",
    "    \n",
    "    #attributs\n",
    "    file = ''\n",
    "    def _init_(self,file):\n",
    "        self.file = file\n",
    "    \n",
    "    \n",
    "    # Méthode\n",
    "    \n",
    "     #Je supprime les colonnes avec 60% de valeurs manquantes\n",
    "    def supprimer_valeur_manquante(self, file,num):\n",
    "        column_with_nan = file.columns[file.isnull().any()]\n",
    "        for column in column_with_nan:\n",
    "             if file[column].isnull().sum()*100.0/file.shape[0] > num:\n",
    "                     file.drop(column,1, inplace=True)\n",
    "        return file\n",
    "    \n",
    "    def Imputation_valeur_manquante(self, file, num):\n",
    "        #Je remplis les valeurs nan par la médiane de la colonnes\n",
    "        column_with_nan = num.columns[num.isnull().any()]\n",
    "\n",
    "        for col in column_with_nan:\n",
    "            file[col].fillna(file[col].median(), inplace = True)\n",
    "        return file\n",
    "    \n",
    "    def Imputation_valeur_manquante2(self, file,cat):\n",
    "        #Je remplis les valeurs nan par le mode de la colonnes catégorielle\n",
    "        column_with_nan = cat.columns[cat.isnull().any()]\n",
    " \n",
    "        for col in column_with_nan:\n",
    "            file[col].fillna(file[col].mode()[0], inplace = True)\n",
    "        return file\n",
    "    \n",
    "\n",
    "    def convert_age(self,age_days_negative):\n",
    "        age_days_positive = - age_days_negative\n",
    "        age_years = age_days_positive/365\n",
    "        return age_years\n",
    "    \n",
    "    def one_hot_encoder(self,file):\n",
    "        cols = list(file.columns)\n",
    "        file = pd.get_dummies(file)\n",
    "        new_cols = [c for c in file.columns if c not in cols]\n",
    "        print('%d columns were one hot encoded.' % len(new_cols))\n",
    "        return file, new_cols\n",
    "    \n",
    "    def label_encoder(self,file):\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        le_count = 0\n",
    "        cols = []\n",
    "\n",
    "        # Iterate through the columns\n",
    "        for col in file:\n",
    "            if col != \"TARGET\":\n",
    "                if file[col].dtype == 'object':\n",
    "                # If 2 or fewer unique categories\n",
    "                    if len(list(file[col].unique())) <= 2 :\n",
    "                        # Train on the training data\n",
    "                        le.fit(file[col])\n",
    "                        # Transform both training and testing data\n",
    "                        file[col] = le.transform(file[col])\n",
    "                        # Keep track of how many columns were label encoded\n",
    "                        le_count += 1\n",
    "                        cols.append(col)\n",
    "\n",
    "        print('%d columns were label encoded.' % le_count)\n",
    "        print('les colonnes sont : %s' % cols)\n",
    "        return file\n",
    "    \n",
    "    def correlation_target(self, file):\n",
    "        # map features to their absolute correlation values\n",
    "        corr = file.corr().abs()\n",
    "        # set equality (self correlation) as zero\n",
    "        corr[corr == 1] = 0\n",
    "        # of each feature, find the max correlation\n",
    "        # and sort the resulting array in ascending order\n",
    "        corr_cols = corr.max().sort_values(ascending=False)\n",
    "        # display the highly correlated features\n",
    "        display(corr_cols[corr_cols > 0.8])\n",
    "\n",
    "        \n",
    "    def display_importances(self, feature_importance_df_):\n",
    "        cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:100].index\n",
    "        best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "        plt.figure(figsize=(15, 20))\n",
    "        sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "        plt.title('LightGBM Features (avg over folds)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('lgbm_importances01.png')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def correlation(self, file,num1,num2):\n",
    "        #prendre les variable quantitative\n",
    "        numerical = file.select_dtypes(include=[np.number]).columns\n",
    "        #matrice de correlation\n",
    "        corr = file[numerical].corr()\n",
    "        #Prendre les index des features\n",
    "        cols_high_corr = corr[((np.abs(corr) > 0.8) & (np.abs(corr) < 1)).any(1)].index\n",
    "        corr_high_corr = file[cols_high_corr].corr()\n",
    "\n",
    "        EDA().correlation_heatmap(corr_high_corr, num1,num2)\n",
    "        \n",
    "        \n",
    "    def suppr_corr(self, file):\n",
    "        #Identify Correlated Variables\n",
    "        # Threshold for removing correlated variables\n",
    "        threshold = 0.8\n",
    "\n",
    "        # Absolute value correlation matrix\n",
    "        corr_matrix = file.corr().abs()\n",
    "        print(\"matrice de correlation head\")\n",
    "        corr_matrix.head()\n",
    "        \n",
    "        upper = corr_matrix.where(\n",
    "        np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "        upper.head()\n",
    "        # Select columns with correlations above threshold\n",
    "        to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "        print('There are %d columns to remove.' % (len(to_drop)))\n",
    "        print('#'*80)\n",
    "        print(to_drop)\n",
    "        file = file.drop(columns=to_drop)\n",
    "        print('shape: ', file.shape)\n",
    "        return to_drop, file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
